---
description: 
globs: 
alwaysApply: false
---
---
description: Tracking of bugs, fixes, and ongoing issues
globs: 
alwaysApply: false
---

# Fixed Issues

## UI/Display Issues
- ✅ Progress dialog not showing during file loading
  - Fixed by ensuring the dialog is created with the right settings in MainWindow._on_load_started
  - Set minimum duration to 0 to show immediately
  - Added explicit visibility commands

- ✅ Data not displaying in table view after loading
  - Fixed the DataView._update_view method to correctly display data from the model
  - Added clearer logs to trace data flow
  - Improved error handling in update methods

- ✅ Multiple file import crashing
  - Fixed progress handling in MultiCSVLoadTask
  - Improved error resilience in _on_load_progress method
  - Added proper error handling for the progress dialog updates

- ✅ Progress dialog consistency issues
  - Enhanced MainWindow._on_load_progress to provide consistent information
  - Added proper tracking of file count, current file, and row progress
  - Improved visibility handling to ensure dialog stays visible throughout the loading process
  - Added more descriptive messages showing file progress (x/y) and row count

- ✅ SyntaxError in progress_bar.py
  - Fixed by removing extraneous backticks (```) at the end of the file
  - This was causing the application to fail at startup

- ✅ Incorrect import in main_window.py
  - Fixed incorrect import path for DataView module
  - Changed from 'chestbuddy.ui.widgets.data_view' to 'chestbuddy.ui.data_view'

- ✅ Missing color constant in progress_dialog.py
  - Fixed reference to non-existent color constant TEXT_PRIMARY
  - Changed to use TEXT_LIGHT which is available in the Colors class

- ✅ Progress dialog not closing properly after table population
  - Fixed the ProgressDialog._on_cancel_clicked method to always close the dialog after emitting the canceled signal
  - Simplified the ProgressDialog.close() method to avoid disconnecting critical signals
  - Updated MainWindow._finalize_loading to avoid breaking the cancel button functionality

- ✅ Multiple dialogs appearing during CSV import
  - Fixed by ensuring only one dialog is used throughout the entire import process
  - Modified DataManager._on_csv_load_success to prevent showing dialog for table population
  - Updated MainWindow._on_load_finished to keep the dialog open for user confirmation

- ✅ Progress dialog inappropriately showing table population status
  - Modified MainWindow._on_load_finished to keep the dialog open for explicit user confirmation
  - Ensured cancel button is renamed to "Close" once loading completes
  - Dialog no longer automatically closes, allowing users to review final status

## Background Processing Issues
- ✅ Signal connections not working properly
  - Fixed connections between DataManager and MainWindow
  - Enhanced signal handling with proper debug logs
  - Improved DataManager._connect_signals() method

- ✅ Progress not updating during file load
  - Fixed by modifying the MultiCSVLoadTask to use a consistent scale
  - Implemented better file-specific progress reporting
  - Added overall progress updates at appropriate points

- ✅ Background worker cleanup issues
  - Improved thread cleanup in BackgroundWorker.__del__
  - Added better error handling for worker cleanup
  - Eliminated forced thread termination during shutdown

- **App crashes during CSV file import**: The application would crash in the middle of processing CSV files, particularly with large files.
  - Fixed by improving the memory management in `csv_service.py`, particularly the `read_csv_chunked` method which now incrementally processes chunks instead of storing all in memory.
  - Added robust error handling for memory errors, allowing partial data recovery.
  - Reduced UI update frequency in progress callbacks to prevent overwhelming the event queue.
  - Improved thread safety and signal handling for cross-thread communication.
  - Added proper resource cleanup and signal disconnection in the `BackgroundWorker` class.
  - Added safeguards against invalid configuration values like chunk size.

## Data Handling Issues
- ✅ ChestDataModel.update_data not notifying correctly
  - Fixed notification logic to ensure data changes are properly communicated
  - Added more detailed logging for debugging

## Data Import Issues

### Multiple Table Repopulation During File Import

**Issue:** When importing multiple files, the table gets repopulated multiple times during the import process, causing visual flickering and potentially slowing down the import process.

**Root Cause:** The `DataManager._on_background_task_completed` method was emitting both a `populate_table_requested` signal and updating the `DataModel`, which caused the table to be populated twice:
1. Once via the `populate_table_requested` signal that triggers `MainWindow._on_populate_table_requested`
2. Again when the `DataModel` emits `data_changed` which triggers `DataView._on_data_changed` to update the view

**Solution:** Removed the redundant `populate_table_requested.emit(mapped_data)` signal from the `DataManager._on_background_task_completed` method, allowing the table to be populated just once via the normal data change notification path.

**Fixed In:** Commit 843d24f

**Status:** Fixed

# Remaining Issues

## Minor Issues
- QThread object deletion warning at shutdown
  - Non-critical issue related to Background Worker cleanup
  - Only occurs during application shutdown and doesn't affect functionality
  - Implemented a more graceful shutdown process to avoid thread termination
  - Improved warning messages to debug level to avoid alarming users

- **Memory usage during large file imports**: While improved, importing very large files still requires significant memory. 
  - Could be further improved by implementing disk-based intermediate storage for extremely large datasets.

## Lessons Learned

1. Signal connections require careful debugging to ensure they're properly connected and functioning
2. Progress reporting should have consistent scales and clear distinction between file-specific and overall progress
3. The Qt progress dialog requires explicit visibility commands in some cases
4. Background task error handling is critical for preventing crashes during file operations
5. Debug logging in key methods greatly assists troubleshooting complex interaction issues
6. Thread cleanup during application shutdown requires special handling to avoid errors
7. Tracking state in a dedicated dictionary (_loading_state) provides more consistent UI updates
8. Processing events (QApplication.processEvents()) is important for responsive UI updates during file operations
9. Check Python files for syntax errors such as extraneous code block markers (```) or incorrect indentation
10. Verify color constants and other resources exist before using them in UI components
11. Keep import paths consistent with actual project structure

- **Memory Management Patterns**: Accumulating chunks of data in memory can lead to crashes with large files. Instead:
  - Process data incrementally where possible
  - Implement early exit strategies for memory errors
  - Add progress throttling to reduce overhead
  - Consider using disk-based intermediate storage for very large datasets

- **Signal Safety**: When working with signals across threads:
  - Use robust error handling around every signal emission
  - Implement throttling for high-frequency progress updates
  - Always disconnect signals when done to prevent memory leaks
  - Use try/except blocks around Qt object interactions that might be deleted

## [2025-03-24] CSV Loading Error

### Issue
CSV loading functionality was failing with an error:
```
Error setting up CSV loading task: BackgroundWorker.execute_task() takes 2 positional arguments but 3 were given
```

### Root Cause
During implementation of progress dialog improvements, the DataManager.load_csv method was modified to call `self._worker.execute_task(task, result_key)` with three arguments, but the BackgroundWorker.execute_task method only accepts two parameters (self and task).

### Solution
1. Fixed the DataManager.load_csv method to call execute_task correctly:
   ```python
   # Changed from
   result_key = "load_csv"
   self._worker.execute_task(task, result_key)
   
   # To
   self._worker.execute_task(task)
   ```

2. Updated the BackgroundWorker._on_thread_started method to properly emit the task_completed signal with the task ID after completion:
   ```python
   task_id = getattr(self._task, "task_id", "unknown")
   self.finished.emit(result)
   self.task_completed.emit(task_id, result)
   ```

3. Enhanced the DataManager._on_background_task_completed method to better handle task results:
   ```python
   if isinstance(result, tuple) and len(result) == 2:
       success, data_or_error = result
       if success and isinstance(data_or_error, pd.DataFrame):
           # Handle successful CSV load
           self._on_csv_load_success((data_or_error, None))
       else:
           # Handle CSV load error
           error_msg = data_or_error if isinstance(data_or_error, str) else str(data_or_error)
           self._on_csv_load_success((None, error_msg))
   ```

### Verification
Tested by loading multiple CSV files, which now works correctly with proper progress reporting.
